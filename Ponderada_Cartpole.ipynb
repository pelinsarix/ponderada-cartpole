{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "257fc7956528482b912e3e2174671831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d1b8e0c3eea4c07b3150f09ea51bd6d",
              "IPY_MODEL_18d9318d94854efab9019a0637534e6d",
              "IPY_MODEL_6f7b8ade03d74c3f9690c12454d8de45"
            ],
            "layout": "IPY_MODEL_8624584313a9412e975f58ac921989a2"
          }
        },
        "2d1b8e0c3eea4c07b3150f09ea51bd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19e270cf50ca4a22a604e2f62ad211e0",
            "placeholder": "​",
            "style": "IPY_MODEL_7c8417595405443f9034f1009e467ca1",
            "value": " 77%"
          }
        },
        "18d9318d94854efab9019a0637534e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7b4693ebbd74de588f7bd01f0f1fa3b",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faddc4e7938b44a4a112c71721cf8cb1",
            "value": 37
          }
        },
        "6f7b8ade03d74c3f9690c12454d8de45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d0c12569c5843919f0c2b9477c9c5f3",
            "placeholder": "​",
            "style": "IPY_MODEL_5210a66820044691a92c57bdbd8b8838",
            "value": " 37/48 [06:55&lt;03:38, 19.83s/it]"
          }
        },
        "8624584313a9412e975f58ac921989a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e270cf50ca4a22a604e2f62ad211e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8417595405443f9034f1009e467ca1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7b4693ebbd74de588f7bd01f0f1fa3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faddc4e7938b44a4a112c71721cf8cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d0c12569c5843919f0c2b9477c9c5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5210a66820044691a92c57bdbd8b8838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1) Instalação de dependências\n",
        "!pip -q install -q gym pyvirtualdisplay tqdm\n",
        "!apt-get update -qq && apt-get install -y xvfb ffmpeg"
      ],
      "metadata": {
        "id": "JDJYJO7AAM-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.bool8 = np.bool_\n",
        "\n",
        "import gym\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "import itertools\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "HA_sKUzrAKhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Configurar display virtual para render no Colab\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "metadata": {
        "id": "H4bx9ISnAPJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Criar ambiente para teste\n",
        "env = gym.make('CartPole-v1')"
      ],
      "metadata": {
        "id": "H9F9-JcbARFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Discretização do espaço de estados contínuo\n",
        "def create_bins():\n",
        "    # Definimos bins para cada dimensão do espaço de observações\n",
        "    bins = [\n",
        "        np.linspace(-4.8, 4.8, 20),      # para a posição do carrinho\n",
        "        np.linspace(-5, 5, 20),          # para a velocidade do carrinho\n",
        "        np.linspace(-0.418, 0.418, 20),  # para o ângulo do bastão em radianos\n",
        "        np.linspace(-5, 5, 20)           # para a velocidade angular do bastão\n",
        "    ]\n",
        "    return bins\n",
        "\n",
        "# Função para discretizar uma observação contínua\n",
        "def discretize(observation, bins):\n",
        "    \"\"\"\n",
        "    Converte um estado contínuo em um estado discreto usando bins predefinidos.\n",
        "\n",
        "    Args:\n",
        "        observation: Array com 4 valores contínuos [posição, velocidade, ângulo, velocidade_angular]\n",
        "        bins: Lista de bins para cada dimensão\n",
        "\n",
        "    Returns:\n",
        "        Tupla com valores discretizados\n",
        "    \"\"\"\n",
        "    return tuple(int(np.digitize(observation[i], bins[i])) for i in range(len(observation)))"
      ],
      "metadata": {
        "id": "Q3T9_6QGAUC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Função para escolher ação usando política epsilon-greedy\n",
        "def choose_action(state, Q, epsilon, action_space):\n",
        "    \"\"\"\n",
        "    Seleciona uma ação usando a política epsilon-greedy.\n",
        "\n",
        "    Args:\n",
        "        state: Estado discretizado atual\n",
        "        Q: Tabela Q\n",
        "        epsilon: Probabilidade de exploração\n",
        "        action_space: Espaço de ações do ambiente\n",
        "\n",
        "    Returns:\n",
        "        Ação escolhida (0 ou 1)\n",
        "    \"\"\"\n",
        "    if np.random.random() < epsilon:\n",
        "        # Exploração: escolhe uma ação aleatória\n",
        "        return action_space.sample()\n",
        "    else:\n",
        "        # Exploração: escolhe a ação com maior valor Q\n",
        "        return np.argmax(Q[state])"
      ],
      "metadata": {
        "id": "0MUELj--AbL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Implementação do Q-learning\n",
        "def q_learning(env, params, verbose=False):\n",
        "    \"\"\"\n",
        "    Implementa o algoritmo Q-learning para o problema CartPole\n",
        "\n",
        "    Args:\n",
        "        env: Ambiente Gym\n",
        "        params: Dicionário com os parâmetros alpha, gamma, epsilon_initial,\n",
        "                epsilon_decay, epsilon_min, num_episodes\n",
        "        verbose: Flag para imprimir informações durante o treinamento\n",
        "\n",
        "    Returns:\n",
        "        Q: Tabela Q treinada\n",
        "        stats: Dicionário com estatísticas do treinamento\n",
        "    \"\"\"\n",
        "    # Extrair parâmetros\n",
        "    alpha = params['alpha']\n",
        "    gamma = params['gamma']\n",
        "    epsilon = params['epsilon_initial']\n",
        "    epsilon_decay = params['epsilon_decay']\n",
        "    epsilon_min = params['epsilon_min']\n",
        "    num_episodes = params['num_episodes']\n",
        "\n",
        "    # Criar bins para discretização\n",
        "    bins = create_bins()\n",
        "\n",
        "    # Inicialização da tabela Q\n",
        "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
        "\n",
        "    # Lista para acompanhar o desempenho\n",
        "    episode_rewards = []\n",
        "    episode_lengths = []\n",
        "\n",
        "    # Loop principal de treinamento\n",
        "    for episode in range(1, num_episodes + 1):\n",
        "        # Reset do ambiente e do estado inicial\n",
        "        reset_output = env.reset()\n",
        "        if isinstance(reset_output, tuple):\n",
        "            state_obs, _ = reset_output\n",
        "        else:\n",
        "            state_obs = reset_output\n",
        "\n",
        "        # Discretiza o estado inicial\n",
        "        state = discretize(state_obs, bins)\n",
        "\n",
        "        # Inicialização de variáveis para o episódio atual\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "        steps = 0\n",
        "\n",
        "        # Loop até o fim do episódio\n",
        "        while not done:\n",
        "            # Escolhe uma ação usando epsilon-greedy\n",
        "            action = choose_action(state, Q, epsilon, env.action_space)\n",
        "\n",
        "            # Executa a ação no ambiente\n",
        "            step_out = env.step(action)\n",
        "            if len(step_out) == 5:\n",
        "                next_state_obs, reward, terminated, truncated, _ = step_out\n",
        "                done = terminated or truncated\n",
        "            else:\n",
        "                next_state_obs, reward, done, _ = step_out\n",
        "\n",
        "            # Discretiza o próximo estado\n",
        "            next_state = discretize(next_state_obs, bins)\n",
        "\n",
        "            # Atualiza a tabela Q usando a equação de Bellman\n",
        "            # Q(s,a) = Q(s,a) + α[r + γ max Q(s',a') - Q(s,a)]\n",
        "            best_next_action = np.argmax(Q[next_state])\n",
        "            td_target = reward + gamma * Q[next_state][best_next_action]\n",
        "            td_error = td_target - Q[state][action]\n",
        "            Q[state][action] += alpha * td_error\n",
        "\n",
        "            # Atualiza o estado atual\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            steps += 1\n",
        "\n",
        "        # Decaimento do epsilon após cada episódio\n",
        "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "\n",
        "        # Armazena métricas para análise\n",
        "        episode_rewards.append(total_reward)\n",
        "        episode_lengths.append(steps)\n",
        "\n",
        "        # Exibe progresso a cada 100 episódios se verbose=True\n",
        "        if verbose and episode % 100 == 0:\n",
        "            avg_reward = np.mean(episode_rewards[-100:])\n",
        "            print(f\"Episódio {episode}/{num_episodes}, Recompensa Média: {avg_reward:.2f}, Epsilon: {epsilon:.4f}\")\n",
        "\n",
        "    # Cálculo de estatísticas finais\n",
        "    stats = {\n",
        "        'avg_reward_last_100': np.mean(episode_rewards[-100:]),\n",
        "        'max_episode_length': max(episode_lengths),\n",
        "        'episode_rewards': episode_rewards,\n",
        "        'episode_lengths': episode_lengths\n",
        "    }\n",
        "\n",
        "    return Q, stats"
      ],
      "metadata": {
        "id": "k7CjUM0kAeec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) Função para avaliar a política aprendida\n",
        "def evaluate_policy(env, Q, num_eval_episodes=10):\n",
        "    \"\"\"\n",
        "    Avalia a política aprendida em novos episódios\n",
        "\n",
        "    Args:\n",
        "        env: Ambiente Gym\n",
        "        Q: Tabela Q treinada\n",
        "        num_eval_episodes: Número de episódios para avaliação\n",
        "\n",
        "    Returns:\n",
        "        float: Recompensa média nos episódios de avaliação\n",
        "    \"\"\"\n",
        "    bins = create_bins()\n",
        "    eval_rewards = []\n",
        "\n",
        "    for _ in range(num_eval_episodes):\n",
        "        reset_output = env.reset()\n",
        "        if isinstance(reset_output, tuple):\n",
        "            obs, _ = reset_output\n",
        "        else:\n",
        "            obs = reset_output\n",
        "        state = discretize(obs, bins)\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not done:\n",
        "            action = np.argmax(Q[state])  # Política gulosa (sem exploração)\n",
        "            step_out = env.step(action)\n",
        "            if len(step_out) == 5:\n",
        "                obs, reward, terminated, truncated, _ = step_out\n",
        "                done = terminated or truncated\n",
        "            else:\n",
        "                obs, reward, done, _ = step_out\n",
        "            state = discretize(obs, bins)\n",
        "            total_reward += reward\n",
        "\n",
        "        eval_rewards.append(total_reward)\n",
        "\n",
        "    return np.mean(eval_rewards)"
      ],
      "metadata": {
        "id": "jLtPUcaCAiC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Função para gerar animação da política treinada\n",
        "def visualize_policy(env, Q):\n",
        "    \"\"\"\n",
        "    Cria uma animação da política aprendida\n",
        "\n",
        "    Args:\n",
        "        env: Ambiente Gym\n",
        "        Q: Tabela Q treinada\n",
        "\n",
        "    Returns:\n",
        "        HTML: Animação da execução da política\n",
        "    \"\"\"\n",
        "    bins = create_bins()\n",
        "    frames = []\n",
        "    reset_output = env.reset()\n",
        "    if isinstance(reset_output, tuple):\n",
        "        obs, _ = reset_output\n",
        "    else:\n",
        "        obs = reset_output\n",
        "    state = discretize(obs, bins)\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        frames.append(env.render(mode='rgb_array'))\n",
        "        action = np.argmax(Q[state])  # Política gulosa (sem exploração)\n",
        "        step_out = env.step(action)\n",
        "        if len(step_out) == 5:\n",
        "            obs, reward, terminated, truncated, _ = step_out\n",
        "            done = terminated or truncated\n",
        "        else:\n",
        "            obs, reward, done, _ = step_out\n",
        "        state = discretize(obs, bins)\n",
        "        total_reward += reward\n",
        "\n",
        "    print(f\"Avaliação: Recompensa total = {total_reward}\")\n",
        "\n",
        "    # Criação da animação\n",
        "    fig = plt.figure(figsize=(8, 6))\n",
        "    patch = plt.imshow(frames[0])\n",
        "    plt.axis('off')\n",
        "\n",
        "    def animate(i):\n",
        "        patch.set_data(frames[i])\n",
        "        return (patch,)\n",
        "\n",
        "    anim = animation.FuncAnimation(fig, animate, frames=len(frames), interval=50)\n",
        "    return HTML(anim.to_jshtml())"
      ],
      "metadata": {
        "id": "Vt2g5FnpAlP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Função para testar múltiplas combinações de parâmetros\n",
        "def grid_search_parameters(param_grid, num_episodes=500, num_eval_episodes=5):\n",
        "    \"\"\"\n",
        "    Realiza uma busca em grade para encontrar os melhores parâmetros\n",
        "\n",
        "    Args:\n",
        "        param_grid: Dicionário com listas de valores para cada parâmetro\n",
        "        num_episodes: Número de episódios para treinamento\n",
        "        num_eval_episodes: Número de episódios para avaliação\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com os resultados da busca\n",
        "        dict: Melhores parâmetros encontrados\n",
        "        object: Tabela Q treinada com os melhores parâmetros\n",
        "    \"\"\"\n",
        "    # Criar todas as combinações possíveis de parâmetros\n",
        "    param_keys = list(param_grid.keys())\n",
        "    param_values = list(param_grid.values())\n",
        "    param_combinations = list(itertools.product(*param_values))\n",
        "\n",
        "    results = []\n",
        "    best_reward = -np.inf\n",
        "    best_params = None\n",
        "    best_Q = None\n",
        "\n",
        "    # Testar cada combinação de parâmetros\n",
        "    print(f\"Testando {len(param_combinations)} combinações de parâmetros...\")\n",
        "\n",
        "    for i, values in enumerate(tqdm(param_combinations)):\n",
        "        params = {\n",
        "            'num_episodes': num_episodes,\n",
        "            **{param_keys[j]: values[j] for j in range(len(param_keys))}\n",
        "        }\n",
        "\n",
        "        # Treinar o agente com os parâmetros atuais\n",
        "        Q, stats = q_learning(env, params)\n",
        "\n",
        "        # Avaliar a política aprendida\n",
        "        eval_reward = evaluate_policy(env, Q, num_eval_episodes)\n",
        "\n",
        "        # Registrar resultados\n",
        "        result = {\n",
        "            **params,\n",
        "            'avg_reward_training': stats['avg_reward_last_100'],\n",
        "            'avg_reward_eval': eval_reward\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Atualizar os melhores parâmetros se necessário\n",
        "        if eval_reward > best_reward:\n",
        "            best_reward = eval_reward\n",
        "            best_params = params.copy()\n",
        "            best_Q = Q\n",
        "\n",
        "    # Criar DataFrame com os resultados\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Ordenar por desempenho de avaliação\n",
        "    results_df = results_df.sort_values('avg_reward_eval', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    return results_df, best_params, best_Q"
      ],
      "metadata": {
        "id": "MyGQT7hgAoy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Definição dos parâmetros a serem testados\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 0.2],  # Taxa de aprendizado\n",
        "    'gamma': [0.95, 0.99, 0.999],  # Fator de desconto\n",
        "    'epsilon_initial': [1.0, 5.0],  # Valor inicial para exploração\n",
        "    'epsilon_decay': [0.99, 0.995],  # Taxa de decaimento do epsilon\n",
        "    'epsilon_min': [0.001, 0.01]  # Valor mínimo do epsilon\n",
        "}"
      ],
      "metadata": {
        "id": "r3N8wU0-Aq8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11) Executar a busca de parâmetros\n",
        "results_df, best_params, best_Q = grid_search_parameters(\n",
        "    param_grid,\n",
        "    num_episodes=3000,  # Reduzido para testes mais rápidos\n",
        "    num_eval_episodes=5\n",
        ")"
      ],
      "metadata": {
        "id": "yN4ks2zgAtZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Mostrar os melhores resultados\n",
        "print(\"\\nMelhores Parâmetros Encontrados:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "print(f\"\\nMelhor Recompensa Média em Avaliação: {results_df.iloc[0]['avg_reward_eval']:.2f}\")"
      ],
      "metadata": {
        "id": "VZOYcHaOAwEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13) Visualizar os resultados em um gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(min(10, len(results_df))), results_df['avg_reward_eval'].head(10))\n",
        "plt.xticks(range(min(10, len(results_df))), [f\"Config {i+1}\" for i in range(min(10, len(results_df)))])\n",
        "plt.title('Top 10 Configurações de Parâmetros')\n",
        "plt.xlabel('Configuração')\n",
        "plt.ylabel('Recompensa Média em Avaliação')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3vFx60tGAzzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14) Treinar o modelo final com os melhores parâmetros\n",
        "print(\"\\nTreinando o modelo final com os melhores parâmetros...\")\n",
        "final_params = best_params.copy()\n",
        "final_params['num_episodes'] = 3000  # Mais episódios para o modelo final\n",
        "final_Q, final_stats = q_learning(env, final_params, verbose=True)"
      ],
      "metadata": {
        "id": "wMEzO2-zA2ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15) Plotar resultados do treinamento final\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "plt.subplot(211)\n",
        "plt.plot(final_stats['episode_rewards'])\n",
        "plt.title('Recompensas por Episódio (Melhores Parâmetros)')\n",
        "plt.xlabel('Episódio')\n",
        "plt.ylabel('Recompensa Total')\n",
        "\n",
        "# Média móvel de 100 episódios\n",
        "window_size = 100\n",
        "moving_avg = np.convolve(final_stats['episode_rewards'], np.ones(window_size)/window_size, mode='valid')\n",
        "plt.plot(range(window_size-1, len(final_stats['episode_rewards'])), moving_avg, 'r-', linewidth=2)\n",
        "plt.legend(['Recompensa por Episódio', 'Média Móvel (100 episódios)'])\n",
        "\n",
        "plt.subplot(212)\n",
        "plt.plot(final_stats['episode_lengths'])\n",
        "plt.title('Duração dos Episódios (Melhores Parâmetros)')\n",
        "plt.xlabel('Episódio')\n",
        "plt.ylabel('Número de Passos')\n",
        "\n",
        "# Média móvel de 100 episódios para duração\n",
        "moving_avg_length = np.convolve(final_stats['episode_lengths'], np.ones(window_size)/window_size, mode='valid')\n",
        "plt.plot(range(window_size-1, len(final_stats['episode_lengths'])), moving_avg_length, 'r-', linewidth=2)\n",
        "plt.legend(['Duração por Episódio', 'Média Móvel (100 episódios)'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gpxsuX-oA6B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16) Visualizar a política final\n",
        "print(\"\\nVisualizando a política final treinada...\")\n",
        "animation_html = visualize_policy(env, final_Q)\n",
        "display(animation_html)"
      ],
      "metadata": {
        "id": "Jk1ZslutA8gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17) Salvar os resultados\n",
        "results_df.to_csv('parameter_search_results.csv', index=False)\n",
        "print(\"Resultados da busca de parâmetros salvos em 'parameter_search_results.csv'\")"
      ],
      "metadata": {
        "id": "4FmDe7bwA-uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18) Exibir tabela com as 5 melhores configurações\n",
        "print(\"\\nTop 5 Melhores Configurações:\")\n",
        "display(results_df.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "257fc7956528482b912e3e2174671831",
            "2d1b8e0c3eea4c07b3150f09ea51bd6d",
            "18d9318d94854efab9019a0637534e6d",
            "6f7b8ade03d74c3f9690c12454d8de45",
            "8624584313a9412e975f58ac921989a2",
            "19e270cf50ca4a22a604e2f62ad211e0",
            "7c8417595405443f9034f1009e467ca1",
            "e7b4693ebbd74de588f7bd01f0f1fa3b",
            "faddc4e7938b44a4a112c71721cf8cb1",
            "6d0c12569c5843919f0c2b9477c9c5f3",
            "5210a66820044691a92c57bdbd8b8838"
          ]
        },
        "id": "CsL0pMys8lI8",
        "outputId": "bfba3f3d-d93f-430f-afcc-935a91ac7b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.14).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 91 not upgraded.\n",
            "Testando 48 combinações de parâmetros...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.11/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/48 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "257fc7956528482b912e3e2174671831"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbYPaH3J_cML"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}